# ðŸŒ PaperBanana

> **Unofficial open-source implementation** of ["PaperBanana: Automating Academic Illustration for AI Scientists"](https://arxiv.org/abs/2601.23265) (Zhu et al.).


[![Try it on HuggingFace Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Samarth0710/PaperBanana)


## Demo

Try PaperBanana directly in your browser â€” no setup required:

**ðŸ”— [huggingface.co/spaces/Samarth0710/PaperBanana](https://huggingface.co/spaces/Samarth0710/PaperBanana)**


## How It Works

<p align="center">
  <img src="docs/method_diagram.png" width="700" />
</p>

<p align="center"><em>PaperBanana pipeline overview â€” figure from <a href="https://arxiv.org/abs/2601.23265">Zhu et al., 2025</a></em></p>

## Installation

```bash
pip install -r requirements.txt
```

Or with [uv](https://docs.astral.sh/uv/):

```bash
uv sync
```

### Setup

Create a `.env` file with your Gemini API key:

```
GEMINI_API_KEY=your-api-key-here
```

## Quick Start

```python
from paperbanana import generate_illustration
from load_reference_set import load_reference_set

ref_set = load_reference_set()  # 100 curated NeurIPS 2025 diagrams

result = generate_illustration(
    methodology_text="Our model uses a Vision Transformer backbone ...",
    caption="Architecture of our proposed vision-language fusion model",
    reference_set=ref_set,
    output_path="output/my_diagram",
)
print(f"Generated: {result['final_image_path']}")
```

<details>
<summary><strong>Advanced usage</strong></summary>

```python
from paperbanana import PaperBanana
from load_reference_set import load_reference_set

pb = PaperBanana(
    reference_set=load_reference_set(),
    mode="diagram",       # or "plot" for statistical plots
    max_iterations=3,
)

result = pb.generate(
    methodology_text=methodology,
    caption=caption,
    output_path="output/diagram",
)

pb.save_history("output/history.json")
```

</details>

## Project Structure

```
paperbanana/
â”œâ”€â”€ paperbanana.py              # Main orchestration
â”œâ”€â”€ app.py                      # Gradio web UI
â”œâ”€â”€ config.py                   # API keys & model config
â”œâ”€â”€ aesthetic_guidelines.py     # NeurIPS-style visual guidelines
â”œâ”€â”€ utils.py                    # Shared utilities
â”œâ”€â”€ load_reference_set.py       # Reference set loader
â”œâ”€â”€ examples.py                 # Runnable examples
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ retriever.py            # Retriever Agent  (VLM-based ranking)
â”‚   â”œâ”€â”€ planner.py              # Planner Agent    (methodology â†’ description)
â”‚   â”œâ”€â”€ stylist.py              # Stylist Agent    (aesthetic refinement)
â”‚   â”œâ”€â”€ visualizer.py           # Visualizer Agent (image generation)
â”‚   â””â”€â”€ critic.py               # Critic Agent     (evaluate & feedback)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ spotlight_reference_set.json
â”‚   â””â”€â”€ spotlight_reference_images/
â”œâ”€â”€ docs/                       # Paper figures & notes
â”œâ”€â”€ examples/                   # Generated output images
â”œâ”€â”€ Dockerfile                  # HF Spaces Docker config
â””â”€â”€ requirements.txt
```

## Configuration

Edit `config.py`:

| Setting | Default | Description |
|---------|---------|-------------|
| `VLM_MODEL` | `gemini-3-pro-preview` | Reasoning model (Retriever, Planner, Stylist, Critic) |
| `IMAGE_MODEL` | `gemini-3-pro-image-preview` | Image generation model (Visualizer) |
| `MAX_REFINEMENT_ITERATIONS` | `3` | Plannerâ†”Critic loop iterations |
| `NUM_REFERENCE_EXAMPLES` | `10` | References retrieved per generation |

## Citation

This is an unofficial implementation. Please cite the original paper:

```bibtex
@article{zhu2025paperbanana,
  title={PaperBanana: Automating Academic Illustration for AI Scientists},
  author={Zhu, Dawei and Meng, Rui and Song, Yale and Wei, Xiyu and Li, Sujian and Pfister, Tomas and Yoon, Jinsung},
  journal={NeurIPS},
  year={2025}
}
```

## License

MIT â€” this implementation is for research and educational purposes.
